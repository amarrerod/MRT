@article{obl,
abstract = {Opposition-based learning as a new scheme for machine intelligence is introduced. Estimates and counter-estimates, weights and opposite weights, and actions versus counter-actions are the foundation of this new approach. Examples are provided. Possibilities for extensions of existing learning algorithms are discussed. Preliminary results are provided},
author = {Tizhoosh, H R},
isbn = {0-7695-2504-0},
journal = {Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, International Conference on},
keywords = {estimation theory,learning (artificial intelligence),machine intelligence,opposition-based learning,optimisation,search problems},
pages = {695--701},
title = {{Opposition-Based Learning: A New Scheme for Machine Intelligence}},
volume = {1},
year = {2005}
}


@book{metaheuristics,
place={Hoboken},
edition={1},
title={Metaheuristics},
publisher={Wiley},
author={Talbi, El-Ghazali},
year={2009}
}

@Article{Segredo2017,
author="Segredo, Eduardo
and Paechter, Ben
and Segura, Carlos
and Gonz{\'a}lez-Vila, Carlos I.",
title="On the comparison of initialisation strategies in differential evolution for large scale optimisation",
journal="Optimization Letters",
year="2017",
pages="1--14",
abstract="Differential Evolution (de) has shown to be a promising global optimisation solver for continuous problems, even for those with a large dimensionality. Different previous works have studied the effects that a population initialisation strategy has on the performance of de when solving large scale continuous problems, and several contradictions have appeared with respect to the benefits that a particular initialisation scheme might provide. Some works have claimed that by applying a particular approach to a given problem, the performance of de is going to be better than using others. In other cases however, researchers have stated that the overall performance of de is not going to be affected by the use of a particular initialisation method. In this work, we study a wide range of well-known initialisation techniques for de. Taking into account the best and worst results, statistically significant differences among considered initialisation strategies appeared. Thus, with the aim of increasing the probability of appearance of high-quality results and/or reducing the probability of appearance of low-quality ones, a suitable initialisation strategy, which depends on the large scale problem being solved, should be selected.",
issn="1862-4480",
}

@ARTICLE{GRASP,
author={Díaz, J.A. and Luna, D.E. and Camacho-Vallejo, J.-F. and Casas-Ramírez, M.-S.},
title={GRASP and hybrid GRASP-Tabu heuristics to solve a maximal covering location problem with customer preference ordering},
journal={Expert Systems with Applications},
year={2017},
volume={82},
pages={67-76},
document_type={Article},
source={Scopus},
}
@ARTICLE{SA,
author={Gerber, M. and Bornn, L.},
title={Improving simulated annealing through derandomization},
journal={Journal of Global Optimization},
year={2017},
volume={68},
number={1},
pages={189-217},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE1,
author={Zheng, L.M. and Zhang, S.X. and Tang, K.S. and Zheng, S.Y.},
title={Differential evolution powered by collective information},
journal={Information Sciences},
year={2017},
volume={399},
pages={13-29},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE2,
author={Fu, C.M. and Jiang, C. and Chen, G.S. and Liu, Q.M.},
title={An adaptive differential evolution algorithm with an aging leader and challengers mechanism},
journal={Applied Soft Computing Journal},
year={2017},
volume={57},
pages={60-73},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE3,
author={Tian, M. and Gao, X. and Dai, C.},
title={Differential evolution with improved individual-based parameter setting and selection strategy},
journal={Applied Soft Computing Journal},
year={2017},
volume={56},
pages={286-297},
document_type={Article},
source={Scopus},
}

@CONFERENCE{CMA,
author={Hajebi, M. and Hoorfar, A. and Bou-Daher, E.},
title={Inverse profiling of inhomogenous buried cylinders with arbitrary cross sections using CMA-ES},
journal={2016 IEEE Antennas and Propagation Society International Symposium, APSURSI 2016 - Proceedings},
year={2016},
pages={863-864},
art_number={7696140},
document_type={Conference Paper},
source={Scopus},
}

@inproceedings{CMA2,
  TITLE = {{Benchmarking a BI-Population CMA-ES on the BBOB-2009 Function Testbed}},
  AUTHOR = {Hansen, Nikolaus},
  BOOKTITLE = {{ACM-GECCO Genetic and Evolutionary Computation Conference}},
  ADDRESS = {Montreal, Canada},
  YEAR = {2009},
  MONTH = Jul,
  HAL_ID = {inria-00382093},
  HAL_VERSION = {v1},
}

@INPROCEEDINGS{CMA1,
author={N. Hansen and A. Ostermeier},
booktitle={Proceedings of IEEE International Conference on Evolutionary Computation},
title={Adapting arbitrary normal mutation distributions in evolution strategies: the covariance matrix adaptation},
year={1996},
pages={312-317},
keywords={genetic algorithms;matrix algebra;arbitrary normal mutation distributions;complex fitness functions;covariance matrix;covariance matrix adaptation;derandomised adaptation;evolution strategies;evolution strategy;evolutionary algorithms;mutation distribution;mutation distributions;rotation invariance;self-adaptation;strategy parameters;Covariance matrix;Electronic switching systems;Evolutionary computation;Genetic mutations;Stochastic processes},
month={May},}

@CONFERENCE{COE1,
author={Atashpendar, A. and Dorronsoro, B. and Danoy, G. and Bouvry, P.},
title={A parallel cooperative coevolutionary SMPSO algorithm for multi-objective optimization},
journal={2016 International Conference on High Performance Computing and Simulation, HPCS 2016},
year={2016},
pages={713-720},
art_number={7568405},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{COE2,
author={Hajikolaei, K.H. and Cheng, G.H. and Wang, G.G.},
title={Optimization on Metamodeling-Supported Iterative Decomposition},
journal={Journal of Mechanical Design, Transactions of the ASME},
year={2016},
volume={138},
number={2},
art_number={021401},
document_type={Article},
source={Scopus},
}

@CONFERENCE{COE3,
author={Glorieux, E. and Svensson, B. and Danielsson, F. and Lennartson, B.},
title={Improved constructive cooperative coevolutionary differential evolution for large-scale optimisation},
journal={Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015},
year={2016},
pages={1703-1710},
art_number={7376815},
document_type={Conference Paper},
source={Scopus},
}

@article{OPSO,
abstract = {Particle Swarm Optimization, a population based optimization technique has been used in wide number of application areas to solve optimization problems. This paper presents a new algorithm for initialization of population in standard PSO called Opposition based Particle Swarm Optimization (O-PSO). The performance of proposed initialization algorithm is compared with the existing PSO variants on several benchmark functions and the experimental results reveal that O-PSO outperforms existing approaches to a large extent.},
author = {Jabeen, Hajira and Jalil, Zunera and Baig, Abdul Rauf},
isbn = {9781605585055},
journal = {Proceedings of the 11th annual conference companion on Genetic and evolutionary computation conference - GECCO '09},
keywords = {initialization,opposition based learning,optimization,pso,swarm intelligence},
pages = {2047},
title = {{Opposition based initialization in particle swarm optimization (O-PSO)}},
year = {2009}
}

@article{OPSO2,
abstract = {Particle swarm optimization (PSO) is a stochastic, population-based optimization method, which has been applied successfully to a wide range of problems. However, PSO is computationally expensive and suffers from premature convergence. In this paper, opposition-based learning is used to improve the performance of PSO. The performance of the proposed approaches is investigated and compared with PSO when applied to eight benchmark functions. The experiments conducted show that opposition-based learning improves the performance of PSO.},
author = {Omran, Mahamed G. H. and Al-Sharhan, Salah},
isbn = {978-1-4244-2704-8},
journal = {2008 IEEE Swarm Intelligence Symposium},
number = {1},
pages = {1--6},
title = {{Using opposition-based learning to improve the performance of particle swarm optimization}},
year = {2008}
}

@article{obl2,
abstract = {Evolutionary algorithms (EAs) are well-known optimization approaches to deal with nonlinear and complex problems. However, these population-based algorithms are computationally expensive due to the slow nature of the evolutionary process. This paper presents a novel algorithm to accelerate the differential evolution (DE). The proposed opposition-based DE (ODE) employs opposition-based learning (OBL) for population initialization and also for generation jumping. In this work, opposite numbers have been utilized to improve the convergence rate of DE. A comprehensive set of 58 complex benchmark functions including a wide range of dimensions is employed for experimental verification. The influence of dimensionality, population size, jumping rate, and various mutation strategies are also investigated. Additionally, the contribution of opposite numbers is empirically verified. We also provide a comparison of ODE to fuzzy adaptive DE (FADE). Experimental results confirm that the ODE outperforms the original DE and FADE in terms of convergence speed and solution accuracy.},
author = {Rahnamayan, Shahryar and Tizhoosh, Hamid R. and Salama, Magdy M.},
isbn = {9783540688273},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
number = {1},
pages = {155--171},
title = {{Opposition-based differential evolution}},
volume = {143},
year = {2008}
}


@article{GPSO,
author = {Pasupuleti, Srinivas and Battiti, Roberto},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation - GECCO '06},
keywords = {differ-,particle swarm algorithm,repeated affine shaker},
number = {0},
pages = {67},
title = {{The gregarious particle swarm optimizer (G-PSO)}},
volume = {1},
year = {2006}
}


@book{metabook,
author = {Du, Ke-Lin and Swamy, M. N. S.},
isbn = {978-3-319-41191-0},
issn = {3319411926},
pages = {327--336},
title = {{Search and Optimization by Metaheuristics}},
year = {2016}
}

@book{Eiben,
author = {A.E. Eiben, J.E. Smith},
isbn = {9783662448748},
pages = {327--336},
title = {{Introduction to Evolutionary Computing}},
year = {2015}
}


@ARTICLE{SA1,
author={Robini, M.C. and Ozon, M. and Frindel, C. and Yang, F. and Zhu, Y.},
title={Global Diffusion Tractography by Simulated Annealing},
journal={IEEE Transactions on Biomedical Engineering},
year={2017},
volume={64},
number={3},
pages={649-660},
art_number={7473911},
document_type={Article},
source={Scopus},
}

@ARTICLE{SA2,
author={Karagiannis, G. and Konomi, B.A. and Lin, G. and Liang, F.},
title={Parallel and interacting stochastic approximation annealing algorithms for global optimisation},
journal={Statistics and Computing},
year={2017},
volume={27},
number={4},
pages={927-945},
document_type={Article},
source={Scopus},
}

@ARTICLE{SA3,
author={Gerber, M. and Bornn, L.},
title={Improving simulated annealing through derandomization},
journal={Journal of Global Optimization},
year={2017},
volume={68},
number={1},
pages={189-217},
document_type={Article},
source={Scopus},
}


@Article{vns,
author="Hansen, Pierre
and Mladenovi{\'{c}}, Nenad
and Moreno P{\'e}rez, Jos{\'e} A.",
title="Variable neighbourhood search: methods and applications",
journal="Annals of Operations Research",
year="2010",
volume="175",
number="1",
pages="367--407",
abstract="Variable neighbourhood search (VNS) is a metaheuristic, or a framework for building heuristics, based upon systematic changes of neighbourhoods both in descent phase, to find a local minimum, and in perturbation phase to emerge from the corresponding valley. It was first proposed in 1997 and has since then rapidly developed both in its methods and its applications. In the present paper, these two aspects are thoroughly reviewed and an extensive bibliography is provided. Moreover, one section is devoted to newcomers. It consists of steps for developing a heuristic for any particular problem. Those steps are common to the implementation of other metaheuristics.",
issn="1572-9338"
}

@ARTICLE{TTRP1,
author={Zheng, W. and Liao, Z. and Qin, J.},
title={Using a four-step heuristic algorithm to design personalized day tour route within a tourist attraction},
journal={Tourism Management},
year={2017},
volume={62},
pages={335-349},
document_type={Article},
source={Scopus},
}

@CONFERENCE{TTRP2,
author={Brito, J. and Expósito-Márquez, A. and Moreno, J.A.},
title={A fuzzy GRASP algorithm for solving a Tourist Trip Design Problem},
journal={IEEE International Conference on Fuzzy Systems},
year={2017},
art_number={8015656},
document_type={Conference Paper},
source={Scopus},
}

@TechReport{LS,
  author={Helena Ramalhinho-Lourenço and Olivier C. Martin and Thomas Stützle},
  title={{Iterated local search}},
  year=2000,
  month=Nov,
  institution={Department of Economics and Business, Universitat Pompeu Fabra},
  type={Economics Working Papers},
  number={513},
  keywords={Metaheuristics; local search; combinatorial optimization},
}

@mastersthesis{marrero,
  document_type     = {Bachelor's Thesis},
  author            = {Marrero Díaz, Alejandro},
  school            = {Universidad de La Laguna},
  year              = {2017},
  title             = {Desarrollo de Algoritmos Dirigidos por Retos},
  month             = {July},
  pdf               = {https://riull.ull.es/xmlui/handle/915/5845},
}
